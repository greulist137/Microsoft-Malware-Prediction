{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameImputer(TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Impute missing values.\n",
    "\n",
    "        Columns of dtype object are imputed with the most frequent value \n",
    "        in column.\n",
    "\n",
    "        Columns of other types are imputed with mean of column.\n",
    "\n",
    "        \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        self.fill = pd.Series([X[c].value_counts().index[0]\n",
    "            if X[c].dtype == np.dtype('O') else X[c].mean() for c in X],\n",
    "            index=X.columns)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newImpute(df):\n",
    "    for col in df.columns:\n",
    "        #print(col)\n",
    "        df[col].fillna(value=df[col].value_counts(),inplace =True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainData = pd.read_csv(\"train.csv\", chunksize=1000)\n",
    "#trainData = pd.read_csv(\"train.csv\")\n",
    "trainData = pd.read_csv(\"train.csv\", nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(trainData['HasDetections'])\n",
    "trainData.drop('HasDetections', inplace = True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = pd.DataFrame(trainData)\n",
    "trainData.drop('MachineIdentifier', inplace = True, axis=1)\n",
    "trainData = DataFrameImputer().fit_transform(trainData)\n",
    "trainData = newImpute(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the decimal columns to full numbers by removing the decimal points\n",
    "trainData.EngineVersion = trainData.EngineVersion.apply(lambda x: x.replace('.',''))\n",
    "trainData.AppVersion = trainData.AppVersion.apply(lambda x: x.replace('.',''))\n",
    "trainData.AvSigVersion = trainData.AvSigVersion.apply(lambda x: x.replace('.',''))\n",
    "trainData.OsVer = trainData.OsVer.apply(lambda x: x.replace('.',''))\n",
    "trainData.Census_OSVersion = trainData.Census_OSVersion.apply(lambda x: x.replace('.',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensuring all of the items are converted to Numeric calues\n",
    "trainData.EngineVersion = pd.to_numeric(trainData.EngineVersion)\n",
    "trainData.AppVersion = pd.to_numeric(trainData.AppVersion)\n",
    "trainData.AvSigVersion = pd.to_numeric(trainData.AvSigVersion)\n",
    "trainData.OsVer = pd.to_numeric(trainData.OsVer)\n",
    "trainData.Census_OSVersion = pd.to_numeric(trainData.Census_OSVersion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "FINISHED\n",
      "(1000, 5465)\n"
     ]
    }
   ],
   "source": [
    "print('Starting')      \n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(trainData)\n",
    "print('FINISHED')\n",
    "trainData = enc.transform(trainData)\n",
    "print(trainData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with Scaler\n",
      "Finished with Scaler\n"
     ]
    }
   ],
   "source": [
    "print('Starting with Scaler')\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "trainData = scaler.fit_transform(trainData)\n",
    "#trainData = pd.DataFrame(trainData)\n",
    "print('Finished with Scaler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = pd.DataFrame(trainData.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5465)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(trainData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-166-98f6fe2f47b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Set hyperparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mn_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mn_h_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mn_h_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mn_h_3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "#Set hyperparameters\n",
    "n_in = X.shape[1]\n",
    "n_h_1 = 100\n",
    "n_h_2 = 50\n",
    "n_h_3 = 25\n",
    "n_out = 1\n",
    "num_epochs=5\n",
    "batch_size = 100\n",
    "learning_rate = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(n_in, n_h_1),\n",
    "                     nn.ReLU(),\n",
    "                    nn.Linear(n_h_1, n_h_2),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(n_h_2, n_h_3),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(n_h_3,n_out),\n",
    "                     nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(50):\n",
    "    # Forward Propagation\n",
    "    y_pred = model(X)\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    print('epoch: ', epoch,' loss: ', loss.item())\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    # perform a backward pass (backpropagation)\n",
    "    loss.backward()\n",
    "    # Update the parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(['ProductName', 'Platform', 'Processor', 'OsPlatformSubRelease',\n",
    "       'OsBuildLab', 'SkuEdition', 'PuaMode', 'SmartScreen',\n",
    "       'Census_MDC2FormFactor', 'Census_DeviceFamily', 'Census_ProcessorClass',\n",
    "       'Census_PrimaryDiskTypeName', 'Census_ChassisTypeName',\n",
    "       'Census_PowerPlatformRoleName', 'Census_InternalBatteryType',\n",
    "       'Census_OSArchitecture', 'Census_OSBranch', 'Census_OSEdition',\n",
    "       'Census_OSSkuName', 'Census_OSInstallTypeName',\n",
    "       'Census_OSWUAutoUpdateOptionsName', 'Census_GenuineStateName',\n",
    "       'Census_ActivationChannel', 'Census_FlightRing'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
