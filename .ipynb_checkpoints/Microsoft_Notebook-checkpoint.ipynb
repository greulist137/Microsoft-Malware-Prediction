{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameImputer(TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Impute missing values.\n",
    "\n",
    "        Columns of dtype object are imputed with the most frequent value \n",
    "        in column.\n",
    "\n",
    "        Columns of other types are imputed with mean of column.\n",
    "\n",
    "        \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        self.fill = pd.Series([X[c].value_counts().index[0]\n",
    "            if X[c].dtype == np.dtype('O') else X[c].mean() for c in X],\n",
    "            index=X.columns)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newImpute(df):\n",
    "    for col in df.columns:\n",
    "        #print(col)\n",
    "        df[col].fillna(value=df[col].value_counts(),inplace =True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = pd.read_csv(\"train.csv\", nrows=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(trainData['HasDetections'], dtype = torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.drop('HasDetections', inplace = True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = pd.DataFrame(trainData)\n",
    "trainData.drop('MachineIdentifier', inplace = True, axis=1)\n",
    "trainData = DataFrameImputer().fit_transform(trainData)\n",
    "trainData = newImpute(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the decimal columns to full numbers by removing the decimal points\n",
    "trainData.EngineVersion = trainData.EngineVersion.apply(lambda x: x.replace('.',''))\n",
    "trainData.AppVersion = trainData.AppVersion.apply(lambda x: x.replace('.',''))\n",
    "trainData.AvSigVersion = trainData.AvSigVersion.apply(lambda x: x.replace('.',''))\n",
    "trainData.OsVer = trainData.OsVer.apply(lambda x: x.replace('.',''))\n",
    "trainData.Census_OSVersion = trainData.Census_OSVersion.apply(lambda x: x.replace('.',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensuring all of the items are converted to Numeric calues\n",
    "trainData.EngineVersion = pd.to_numeric(trainData.EngineVersion)\n",
    "trainData.AppVersion = pd.to_numeric(trainData.AppVersion)\n",
    "trainData.AvSigVersion = pd.to_numeric(trainData.AvSigVersion)\n",
    "trainData.OsVer = pd.to_numeric(trainData.OsVer)\n",
    "trainData.Census_OSVersion = pd.to_numeric(trainData.Census_OSVersion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 81)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "FINISHED\n",
      "(10000, 24072)\n"
     ]
    }
   ],
   "source": [
    "print('Starting')      \n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(trainData)\n",
    "print('FINISHED')\n",
    "trainData = enc.transform(trainData)\n",
    "print(trainData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with Scaler\n",
      "Finished with Scaler\n"
     ]
    }
   ],
   "source": [
    "print('Starting with Scaler')\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "trainData = scaler.fit_transform(trainData)\n",
    "#trainData = pd.DataFrame(trainData)\n",
    "print('Finished with Scaler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = pd.DataFrame(trainData.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 24072)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\greul\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "trainData = trainData.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(trainData, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 24072)\n"
     ]
    }
   ],
   "source": [
    "print(trainData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 24072])\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24072"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set hyperparameters\n",
    "n_in = X.shape[1]\n",
    "n_h_1 = 100\n",
    "n_h_2 = 50\n",
    "n_h_3 = 25\n",
    "n_out = 1\n",
    "num_epochs=5\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(n_in, n_h_1),\n",
    "                     nn.ReLU(),\n",
    "                        nn.Dropout(0.5),\n",
    "                    nn.Linear(n_h_1, n_h_2),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(0.5),\n",
    "                      nn.Linear(n_h_2, n_h_3),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(0.5),\n",
    "                      nn.Linear(n_h_3,n_out),\n",
    "                     nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Variable(X).float()\n",
    "y = Variable(y).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  loss:  0.2508845031261444\n",
      "epoch:  1  loss:  0.25085389614105225\n",
      "epoch:  2  loss:  0.25084641575813293\n",
      "epoch:  3  loss:  0.25087010860443115\n",
      "epoch:  4  loss:  0.25087982416152954\n",
      "epoch:  5  loss:  0.25089266896247864\n",
      "epoch:  6  loss:  0.25086286664009094\n",
      "epoch:  7  loss:  0.250852108001709\n",
      "epoch:  8  loss:  0.2508511245250702\n",
      "epoch:  9  loss:  0.25086864829063416\n",
      "epoch:  10  loss:  0.2508472800254822\n",
      "epoch:  11  loss:  0.2508719265460968\n",
      "epoch:  12  loss:  0.250850111246109\n",
      "epoch:  13  loss:  0.2508699595928192\n",
      "epoch:  14  loss:  0.25086379051208496\n",
      "epoch:  15  loss:  0.25084206461906433\n",
      "epoch:  16  loss:  0.2508547008037567\n",
      "epoch:  17  loss:  0.2508462071418762\n",
      "epoch:  18  loss:  0.25082963705062866\n",
      "epoch:  19  loss:  0.2508193254470825\n",
      "epoch:  20  loss:  0.25082242488861084\n",
      "epoch:  21  loss:  0.25083646178245544\n",
      "epoch:  22  loss:  0.25080934166908264\n",
      "epoch:  23  loss:  0.2508416771888733\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    # Forward Propagation\n",
    "    model.train()\n",
    "    y_pred = model(X)\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    print('epoch: ', epoch,' loss: ', loss.item())\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    # perform a backward pass (backpropagation)\n",
    "    loss.backward()\n",
    "    # Update the parameters\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"checkpoint.pth.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
