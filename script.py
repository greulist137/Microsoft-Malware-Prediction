#Import Libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
import torch
from torchvision import datasets, transforms, models
import torch.nn as nn
import torchvision.datasets as dsets
import torchvision.transforms as transforms
from torch.autograd import Variable
from sklearn.decomposition import PCA
from sklearn.preprocessing import Imputer
from sklearn.base import TransformerMixin
from sklearn.preprocessing import OneHotEncoder


class DataFrameImputer(TransformerMixin):

    def __init__(self):
        """Impute missing values.

        Columns of dtype object are imputed with the most frequent value 
        in column.

        Columns of other types are imputed with mean of column.

        """
    def fit(self, X, y=None):

        self.fill = pd.Series([X[c].value_counts().index[0]
            if X[c].dtype == np.dtype('O') else X[c].mean() for c in X],
            index=X.columns)

        return self

    def transform(self, X, y=None):
        return X.fillna(self.fill)
    
    
def newImpute(df):
    for col in df.columns:
        #print(col)
        df[col].fillna(value=df[col].value_counts(),inplace =True)
    return df
   

#trainData = pd.read_csv("train.csv", nrows=10000)
trainData = pd.read_csv("train.csv")

y = torch.tensor(trainData['HasDetections'], dtype = torch.float64)

trainData.drop('HasDetections', inplace = True, axis=1)

trainData = pd.DataFrame(trainData)
trainData.drop('MachineIdentifier', inplace = True, axis=1)
trainData = DataFrameImputer().fit_transform(trainData)
trainData = newImpute(trainData)


#Converting the decimal columns to full numbers by removing the decimal points
trainData.EngineVersion = trainData.EngineVersion.apply(lambda x: x.replace('.',''))
trainData.AppVersion = trainData.AppVersion.apply(lambda x: x.replace('.',''))
trainData.AvSigVersion = trainData.AvSigVersion.apply(lambda x: x.replace('.',''))
trainData.OsVer = trainData.OsVer.apply(lambda x: x.replace('.',''))
trainData.Census_OSVersion = trainData.Census_OSVersion.apply(lambda x: x.replace('.',''))


#Ensuring all of the items are converted to Numeric calues
trainData.EngineVersion = pd.to_numeric(trainData.EngineVersion)
trainData.AppVersion = pd.to_numeric(trainData.AppVersion)
trainData.AvSigVersion = pd.to_numeric(trainData.AvSigVersion)
trainData.OsVer = pd.to_numeric(trainData.OsVer)
trainData.Census_OSVersion = pd.to_numeric(trainData.Census_OSVersion)

print(trainData.shape)

print(type(trainData))

encoder = OneHotEncoder()

print('Starting')      
enc = OneHotEncoder(handle_unknown='ignore')
enc.fit(trainData)
print('FINISHED')
trainData = enc.transform(trainData)
print(trainData.shape)

print('Starting with Scaler')
scaler = StandardScaler(with_mean=False)
trainData = scaler.fit_transform(trainData)
#trainData = pd.DataFrame(trainData)
print('Finished with Scaler')

trainData = pd.DataFrame(trainData.toarray())

print(type(trainData))

print(trainData.shape)

trainData = trainData.as_matrix()

X = torch.tensor(trainData, dtype=torch.float64)

print(trainData.shape)

print(X.shape)

print(y.shape)

print(X.shape[1])

print(y.dtype)

print(X.dtype)

#Set hyperparameters
n_in = X.shape[1]
n_h_1 = 100
n_h_2 = 50
n_h_3 = 25
n_out = 1
num_epochs=5
batch_size = 100
learning_rate = 0.01

model = nn.Sequential(nn.Linear(n_in, n_h_1),
                     nn.ReLU(),
                    nn.Linear(n_h_1, n_h_2),
                      nn.ReLU(),
                      nn.Linear(n_h_2, n_h_3),
                      nn.ReLU(),
                      nn.Linear(n_h_3,n_out),
                     nn.Sigmoid())

criterion = torch.nn.MSELoss()

optimizer = torch.optim.SGD(model.parameters(), lr=0.03)



X = Variable(X).float()
y = Variable(y).float()


for epoch in range(50):
    # Forward Propagation
    model.train()
    y_pred = model(X)
    # Compute and print loss
    loss = criterion(y_pred, y)
    print('epoch: ', epoch,' loss: ', loss.item())
    # Zero the gradients
    optimizer.zero_grad()
    # perform a backward pass (backpropagation)
    loss.backward()
    # Update the parameters
    optimizer.step()
    optimizer.zero_grad()
    
  model.save_state_dict('mytraining.pt')